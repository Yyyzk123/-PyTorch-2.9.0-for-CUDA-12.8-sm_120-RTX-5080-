name: Test Install PyTorch & torchvision Wheels

on:
  push:
    branches: [ main ]
  pull_request:
    branches: [ main ]

jobs:
  install-test:
    runs-on: ubuntu-latest

    # 使用官方 CUDA 12.8.1 + cuDNN Ubuntu 24.04 运行时镜像（2025/08/04 已存在）
    container:
      image: nvidia/cuda:12.8.1-cudnn-runtime-ubuntu24.04

    steps:
    # 0️⃣ 取仓库代码
    - name: Checkout repository
      uses: actions/checkout@v4
      
    # 1️⃣ 添加 NVIDIA cuDNN 9 APT 仓库并安装（兼容 CUDA 12.8，Ubuntu 24.04 原生支持）
    - name: Install system & cuDNN 9 runtime
      run: |
        set -e
        apt-get update -qq
    
        # ==== ① 基础依赖 ====
        apt-get install -y --no-install-recommends \
            wget curl ca-certificates bzip2 \
            libnuma1 libgomp1 libopenblas0-pthread python3-pip
    
        # ==== ② cuDNN 9 公钥 & 源 ====
        wget -qO- https://developer.download.nvidia.com/compute/cudnn/repos/ubuntu2404/x86_64/cudnn-ubuntu2404.key \
          | tee /etc/apt/trusted.gpg.d/cudnn.gpg
        echo "deb https://developer.download.nvidia.com/compute/cudnn/repos/ubuntu2404/x86_64/ /" \
          | tee /etc/apt/sources.list.d/cudnn.list
    
        apt-get update -qq
    
        # ==== ③ 安装与 CUDA-12.8 匹配的 cuDNN 9 ====
        # 用 apt-cache 取最新 9.* 版本号（兼容所有 CUDA 12.x，包括 12.8）
        CUDNN_VER=$(apt-cache madison libcudnn9-cuda-12 | awk '{print $3}' | head -1)
        echo "Installing cuDNN version: $CUDNN_VER"
        apt-get install -y --no-install-recommends \
            libcudnn9-cuda-12="$CUDNN_VER" \
            libcudnn9-dev-cuda-12="$CUDNN_VER"
        
    # 2️⃣ 安装 micromamba 并创建 Python 3.10 环境（超快）
    - name: Set up micromamba (Python 3.10)
      run: |
        curl -Ls https://micro.mamba.pm/api/micromamba/linux-64/latest | tar -xvj bin/micromamba
        ./bin/micromamba create -y -p $HOME/py310 python=3.10
        echo "$HOME/py310/bin" >> $GITHUB_PATH
        export PATH="$HOME/py310/bin:$PATH"  # 显式 export，确保后续步骤可用

    # 3️⃣ 下载最新 Release 中的两个 .whl 文件（torch & torchvision）
    - name: Download wheels from latest GitHub Release
      id: download
      run: |
        set -e
        mkdir -p dist
        REPO="${{ github.repository }}"
        WHL_URLS=$(curl -s https://api.github.com/repos/$REPO/releases/latest \
          | grep browser_download_url | grep '.whl"' | cut -d '"' -f 4)
        echo "Found wheels:"
        echo "$WHL_URLS"
        for URL in $WHL_URLS; do
          FILE=$(basename "$URL")
          echo "↓ $FILE"
          wget -q "$URL" -O dist/"$FILE"
          sha256sum dist/"$FILE"
        done

    # 4️⃣ 安装 .whl 与其他依赖
    - name: Install wheels & Python deps
      run: |
        export PATH="$HOME/py310/bin:$PATH"
        python -m pip install dist/torch-*.whl
        python -m pip install dist/torchvision-*.whl
        python -m pip install -r requirements.txt

    # 5️⃣ 运行 Demo & 打印环境信息
    - name: Verify installation
      run: |
        export PATH="$HOME/py310/bin:$PATH"
        python examples/demo_tensor_cuda.py || true
        python - <<'PY'
        import torch, platform, sys
        print("Python  :", platform.python_version())
        print("Torch   :", torch.__version__)
        print("CUDA OK :", torch.cuda.is_available())
        if torch.cuda.is_available():
            print("GPU Name:", torch.cuda.get_device_name(0))
            print("sm arch :", torch.cuda.get_device_capability())
        else:
            print("GPU Name: (no GPU, CI runner)")
        print("TorchVision:", __import__('torchvision').__version__)
        PY

    - name: Final result
      run: echo "✅ CI completed — wheels install successfully!"
