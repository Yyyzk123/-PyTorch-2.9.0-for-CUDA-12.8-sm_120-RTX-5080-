name: Test Install PyTorch & torchvision Wheels

on:
  push:
    branches: [ main ]
  pull_request:
    branches: [ main ]

jobs:
  install-test:
    runs-on: ubuntu-latest

    # 使用官方 CUDA 12.8.1 + cuDNN Ubuntu 24.04 运行时镜像
    container:
      image: nvidia/cuda:12.8.1-cudnn-runtime-ubuntu24.04

    steps:
    # 0️⃣ 取仓库代码
    - name: Checkout repository
      uses: actions/checkout@v4

    # 1️⃣ 安装基础系统依赖
    - name: Install system packages
      run: |
        set -e
        apt-get update -qq
        # 追加 libcudnn8
        apt-get install -y --no-install-recommends \
            wget curl ca-certificates bzip2 \
            libnuma1 libgomp1 libopenblas0-pthread \
            python3-pip \
            libcudnn8=8.9.7.*-1+cuda12.4
    # 2️⃣ 安装 micromamba 并创建 Python 3.10 环境（超快）
    - name: Set up micromamba (Python 3.10)
      run: |
        curl -Ls https://micro.mamba.pm/api/micromamba/linux-64/latest | tar -xvj bin/micromamba
        ./bin/micromamba create -y -p $HOME/py310 python=3.10
        echo "$HOME/py310/bin" >> $GITHUB_PATH

    # 3️⃣ 下载最新 Release 中的两个 .whl 文件（torch & torchvision）
    - name: Download wheels from latest GitHub Release
      id: download
      run: |
        set -e
        mkdir -p dist
        REPO="${{ github.repository }}"
        WHL_URLS=$(curl -s https://api.github.com/repos/$REPO/releases/latest \
          | grep browser_download_url | grep '.whl"' | cut -d '"' -f 4)
        echo "Found wheels:"
        echo "$WHL_URLS"
        for URL in $WHL_URLS; do
          FILE=$(basename "$URL")
          echo "↓ $FILE"
          wget -q "$URL" -O dist/"$FILE"
          sha256sum dist/"$FILE"
        done

    # 4️⃣ 安装 .whl 与其他依赖
    - name: Install wheels & Python deps
      run: |
        python -m pip install dist/torch-*.whl
        python -m pip install dist/torchvision-*.whl
        python -m pip install -r requirements.txt

    # 5️⃣ 运行 Demo & 打印环境信息
    - name: Verify installation
      run: |
        python examples/demo_tensor_cuda.py || true
        python - <<'PY'
        import torch, platform, sys
        print("Python  :", platform.python_version())
        print("Torch   :", torch.__version__)
        print("CUDA OK :", torch.cuda.is_available())
        if torch.cuda.is_available():
            print("GPU Name:", torch.cuda.get_device_name(0))
            print("sm arch :", torch.cuda.get_device_capability())
        else:
            print("GPU Name: (no GPU, CI runner)")
        print("TorchVision:", __import__('torchvision').__version__)
        PY

    - name: Final result
      run: echo "✅ CI completed — wheels install successfully!"
