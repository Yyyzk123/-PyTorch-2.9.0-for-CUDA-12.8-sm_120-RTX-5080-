name: Test Install PyTorch & torchvision Wheels

on:
  push:
    branches: [ main ]
  pull_request:
    branches: [ main ]

jobs:
  install-test:
    runs-on: ubuntu-latest

    container:
      image: nvidia/cuda:12.8.1-cudnn-devel-ubuntu24.04

    steps:
    - name: Checkout repository
      uses: actions/checkout@v4
      
    - name: Install system deps & cuDNN 8 tarball
      run: |
        set -e
        apt-get update -qq
        
        # 修复 ldconfig segfault (Ubuntu 24.04 Docker bug, root 无 sudo)
        dpkg --configure -a || true
        apt-get install -f -y || true
        rm -f /var/cache/ldconfig/aux-cache
        apt-get purge libc-bin libc6 -y || true
        apt-get install --reinstall libc-bin libc6 -y || true
        /sbin/ldconfig || true
        apt-get clean
        
        # 最小依赖（避免 triggers）
        apt-get install -y --no-install-recommends \
            wget curl ca-certificates python3-pip tar
        
        # 安装 cuDNN 8.9.7 tarball（wheel 硬依赖 libcudnn.so.8）
        tar -xvf cudnn/cudnn-linux-x86_64-8.9.7.29_cuda12-archive.tar.xz
        cp -P cudnn-linux-x86_64-8.9.7.29_cuda12-archive/include/* /usr/local/cuda/include/
        cp -P cudnn-linux-x86_64-8.9.7.29_cuda12-archive/lib/* /usr/local/cuda/lib64/
        chmod a+r /usr/local/cuda/lib64/libcudnn*
        /sbin/ldconfig
        echo "cuDNN installed: $(ls /usr/local/cuda/lib64/libcudnn.so.*)"
        
    - name: Set up micromamba (Python 3.10)
      run: |
        curl -Ls https://micro.mamba.pm/api/micromamba/linux-64/latest | tar -xvj bin/micromamba
        ./bin/micromamba create -y -p $HOME/py310 python=3.10
        echo "$HOME/py310/bin" >> $GITHUB_PATH
        export PATH="$HOME/py310/bin:$PATH"

    - name: Download wheels from latest GitHub Release
      id: download
      run: |
        set -e
        mkdir -p dist
        REPO="${{ github.repository }}"
        WHL_URLS=$(curl -s https://api.github.com/repos/$REPO/releases/latest \
          | grep browser_download_url | grep '.whl"' | cut -d '"' -f 4)
        echo "Found wheels:"
        echo "$WHL_URLS"
        for URL in $WHL_URLS; do
          FILE=$(basename "$URL")
          echo "↓ $FILE"
          wget -q "$URL" -O dist/"$FILE"
          sha256sum dist/"$FILE"
        done

    - name: Install wheels & Python deps
      run: |
        export PATH="$HOME/py310/bin:$PATH"
        python -m pip install dist/torch-*.whl
        python -m pip install dist/torchvision-*.whl
        python -m pip install -r requirements.txt

    - name: Verify installation
      run: |
        export PATH="$HOME/py310/bin:$PATH"
        python examples/demo_tensor_cuda.py || true
        python - <<'PY'
        import torch, platform, sys
        print("Python  :", platform.python_version())
        print("Torch   :", torch.__version__)
        print("CUDA OK :", torch.cuda.is_available())
        if torch.cuda.is_available():
            print("GPU Name:", torch.cuda.get_device_name(0))
            print("sm arch :", torch.cuda.get_device_capability())
        else:
            print("GPU Name: (no GPU, CI runner)")
        print("TorchVision:", __import__('torchvision').__version__)
        PY

    - name: Final result
      run: echo "✅ CI completed — wheels install successfully!"
