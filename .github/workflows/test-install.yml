name: Test Install PyTorch & torchvision Wheels

on:
  push:
    branches: [ main ]
  pull_request:
    branches: [ main ]

jobs:
  install-test:
    runs-on: ubuntu-latest

    # 使用官方 CUDA 12.8.1 + cuDNN Ubuntu 24.04 运行时镜像
    container:
      image: nvidia/cuda:12.8.1-cudnn-runtime-ubuntu24.04

    steps:
    # 0️⃣ 取仓库代码
    - name: Checkout repository
      uses: actions/checkout@v4
      
    # 1️⃣ 安装系统依赖 & cuDNN 9 via tarball（Ubuntu 24.04 无 network repo）
    - name: Install system & cuDNN 9 tarball
      run: |
        set -e
        apt-get update -qq
    
        # ==== ① 基础依赖 ====
        apt-get install -y --no-install-recommends \
            wget curl ca-certificates bzip2 \
            libnuma1 libgomp1 libopenblas0-pthread python3-pip tar
        
        # ==== ② 下载 & 安装 cuDNN 9 tarball (latest 9.3.0 for CUDA 12.x) ====
        CUDNN_VERSION="9.3.0.75"
        wget -q https://developer.download.nvidia.com/compute/cudnn/9.3.0/local_installers/9.3.0/cudnn-linux-x86_64-${CUDNN_VERSION}_cuda12-archive.tar.xz
        tar -xvf cudnn-linux-x86_64-${CUDNN_VERSION}_cuda12-archive.tar.xz
        sudo cp -P cudnn-linux-x86_64-${CUDNN_VERSION}_cuda12-archive/include/* /usr/local/cuda/include/
        sudo cp -P cudnn-linux-x86_64-${CUDNN_VERSION}_cuda12-archive/lib/* /usr/local/cuda/lib64/
        sudo chmod a+r /usr/local/cuda/lib64/libcudnn*
        sudo ldconfig
        echo "cuDNN installed: $(ls /usr/local/cuda/lib64/libcudnn.so.*)"
        
    # 2️⃣ 安装 micromamba 并创建 Python 3.10 环境（超快）
    - name: Set up micromamba (Python 3.10)
      run: |
        curl -Ls https://micro.mamba.pm/api/micromamba/linux-64/latest | tar -xvj bin/micromamba
        ./bin/micromamba create -y -p $HOME/py310 python=3.10
        echo "$HOME/py310/bin" >> $GITHUB_PATH
        export PATH="$HOME/py310/bin:$PATH"  # 显式 export，确保后续可用

    # 3️⃣ 下载最新 Release 中的两个 .whl 文件（torch & torchvision）
    - name: Download wheels from latest GitHub Release
      id: download
      run: |
        set -e
        mkdir -p dist
        REPO="${{ github.repository }}"
        WHL_URLS=$(curl -s https://api.github.com/repos/$REPO/releases/latest \
          | grep browser_download_url | grep '.whl"' | cut -d '"' -f 4)
        echo "Found wheels:"
        echo "$WHL_URLS"
        for URL in $WHL_URLS; do
          FILE=$(basename "$URL")
          echo "↓ $FILE"
          wget -q "$URL" -O dist/"$FILE"
          sha256sum dist/"$FILE"
        done

    # 4️⃣ 安装 .whl 与其他依赖
    - name: Install wheels & Python deps
      run: |
        export PATH="$HOME/py310/bin:$PATH"
        python -m pip install dist/torch-*.whl
        python -m pip install dist/torchvision-*.whl
        python -m pip install -r requirements.txt

    # 5️⃣ 运行 Demo & 打印环境信息
    - name: Verify installation
      run: |
        export PATH="$HOME/py310/bin:$PATH"
        python examples/demo_tensor_cuda.py || true
        python - <<'PY'
        import torch, platform, sys
        print("Python  :", platform.python_version())
        print("Torch   :", torch.__version__)
        print("CUDA OK :", torch.cuda.is_available())
        if torch.cuda.is_available():
            print("GPU Name:", torch.cuda.get_device_name(0))
            print("sm arch :", torch.cuda.get_device_capability())
        else:
            print("GPU Name: (no GPU, CI runner)")
        print("TorchVision:", __import__('torchvision').__version__)
        PY

    - name: Final result
      run: echo "✅ CI completed — wheels install successfully!"
