# ğŸ¤ Contributing to PyTorch 2.9.0 (CUDA 12.8 + sm_120)

Welcome! ğŸ‘‹ We appreciate your interest in contributing to this project.

This project provides a pre-built PyTorch 2.9.0 package for CUDA 12.8 with sm_120 (Ada, RTX 5080) support. Verified on Gaussian Splatting, SplaTAM, and more.

---

## ğŸ“¦ How to Contribute Code

### 1. Fork the Repository
Click the `Fork` button at the top right of this page.

### 2. Clone Your Fork
```bash
git clone https://github.com/YOUR_USERNAME/pytorch-cuda128-sm120.git
cd pytorch-cuda128-sm120
```

### 3. Create a New Branch
```bash
git checkout -b feature/your-feature-name
```

### 4. Make Your Changes
If youâ€™re modifying build scripts or configs, please also:
> Run build_pytorch.sh to ensure .whl builds successfully.
> Run examples/verify_install.py to confirm installation is correct.

### 5. Commit and Push
```bash
git add .
git commit -m "Add: describe your change clearly"
git push origin feature/your-feature-name
```
### 6. Open a Pull Request
Go to your fork â†’ Switch to your branch â†’ Click â€œCompare & Pull Requestâ€

ğŸ“š Code Style & Guidelines
âœ… Use clear, concise commit messages
âœ… Add comments if modifying scripts
âœ… Don't commit .whl or large binary files
âœ… Keep README.md and build_info.md in sync if relevant

ğŸ Reporting Issues
Please open an issue and include:
System info (nvidia-smi, nvcc --version)
Error logs (full stack trace if any)
Steps to reproduce (optional but helpful)

ğŸ™Œ Thanks for Your Contribution!
Letâ€™s build a faster and better CUDA PyTorch experience together ğŸ’ª


